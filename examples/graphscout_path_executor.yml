name: "GraphScout + PathExecutor Integration"
description: |
  Advanced example demonstrating GraphScout with PathExecutor.
  
  **How GraphScout Works:**
  - GraphScout automatically discovers agents from the orchestrator's agent list
  - It uses beam search + LLM evaluation to find optimal paths
  - Agents MUST have `capabilities` tags for GraphScout to evaluate them
  - The prompt should be minimal - GraphScout does the path selection internally
  
  **Workflow:**
  1. Validation loop: GraphScout proposes paths, PlanValidator validates them
  2. Loop continues until validation score meets threshold (0.80)
  3. PathExecutor executes the validated agent sequence
  
  This is the RECOMMENDED pattern for production-grade validated execution.

orchestrator:
  id: graphscout-path-executor
  strategy: sequential
  agents:
    - validation_loop
    - path_executor
    - final_summary

agents:
  # PHASE 1: Validate the path with a loop
  - id: validation_loop
    type: loop
    max_loops: 3  # Force stop after 3 iterations
    persist_across_runs: false  # Prevent infinite accumulation across workflow runs
    score_threshold: 0.5  # Exit if score reaches this
    # No exit_condition - rely on max_loops for guaranteed termination
    
    internal_workflow:
      orchestrator:
        id: validation-internal
        strategy: sequential
        agents: [graphscout_router, path_validator]
      
      agents:
        # GraphScout proposes optimal path from available agents
        - id: graphscout_router
          type: graph-scout
          params:
            k_beam: 5
            max_depth: 3
            commit_margin: 0.1
            require_terminal: true
            safety_profile: "permissive"  # Disable overly strict safety checks
            safety_threshold: 0.5  # Don't block paths on safety violations
            score_weights:
              llm: 0.5
              heuristics: 0.3
              prior: 0.15
              cost: 0.025
              latency: 0.025
            evaluation_model: "local_llm"
            evaluation_model_name: "gpt-oss:20b"
          prompt: |
            Query: {{ input }}
            
            {% if has_past_loops() and get_past_loops()|length > 0 %}
            ## Validation Feedback (Iteration {{ get_loop_number() }})
            {% set last_loop = get_past_loops()[-1] %}
            Previous validation score: {{ last_loop.score|default('N/A') }}
            
            {% if last_loop.mistakes and last_loop.mistakes|length > 0 %}
            Issues to address:
            {% if "has_all_required_steps" in last_loop.mistakes %}
            - Missing required steps - ensure complete workflow
            {% endif %}
            {% if "uses_appropriate_agents" in last_loop.mistakes %}
            - Suboptimal agent selection - review agent capabilities
            {% endif %}
            {% if "includes_fallback_path" in last_loop.mistakes %}
            - Add error handling and fallback paths
            {% endif %}
            {% endif %}
            {% endif %}
            
            Select optimal path from available agents.
        
        # PlanValidator validates the path
        - id: path_validator
          type: plan_validator
          llm_model: "gpt-oss:20b"
          llm_provider: "ollama"
          llm_url: "http://localhost:11434/api/generate"
          temperature: 0.2
          scoring_preset: "moderate"
          custom_weights:
            completeness.has_all_required_steps: 0.15
            efficiency.uses_appropriate_agents: 0.15
            safety.handles_errors_gracefully: 0.10

  # ===== EXECUTION AGENTS (Top Level) =====
  # These agents are available for GraphScout to discover and PathExecutor to execute
  # They are NOT in the orchestrator sequence, so they won't auto-execute
  
  - id: web_search
    type: duckduckgo
    capabilities: [data_retrieval, web_search]
    prompt: |
      {{ input }}
  
  - id: deep_analyzer
    type: local_llm
    capabilities: [reasoning, analysis, deep_thinking]
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.4
    prompt: |
      Provide deep, multi-perspective analysis of: {{ input }}
      
      {% if previous_outputs.web_search %}
      Search Context: {{ previous_outputs.web_search.result }}
      {% endif %}
      
      Consider multiple viewpoints and provide comprehensive insights.
  
  - id: technical_expert
    type: local_llm
    capabilities: [technical_analysis, expertise, domain_knowledge]
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.3
    prompt: |
      Provide expert technical analysis for: {{ input }}
      
      Available Context: {{ previous_outputs }}
      
      Focus on technical accuracy and domain expertise.
  
  - id: content_writer
    type: local_llm
    capabilities: [answer_emit, content_generation, writing]
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.5
    prompt: |
      Create comprehensive, well-written content for: {{ input }}
      
      {% if previous_outputs.web_search %}
      Research: {{ previous_outputs.web_search }}
      {% endif %}
      {% if previous_outputs.deep_analyzer %}
      Analysis: {{ previous_outputs.deep_analyzer.response }}
      {% endif %}
      {% if previous_outputs.technical_expert %}
      Technical Input: {{ previous_outputs.technical_expert.response }}
      {% endif %}
      
      Generate clear, engaging, and accurate content.
  
  - id: fact_checker
    type: local_llm
    capabilities: [verification, validation, fact_checking]
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.2
    prompt: |
      Verify the accuracy of information:
      
      Content: {{ previous_outputs }}
      
      Check for factual errors, inconsistencies, and provide corrections if needed.
  
  - id: quality_reviewer
    type: local_llm
    capabilities: [quality_assessment, review, critique]
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.3
    prompt: |
      Review the quality of outputs:
      
      Results: {{ previous_outputs }}
      
      Assess completeness, accuracy, clarity, and overall quality.
      Provide improvement suggestions if needed.
  
  # PHASE 2: Execute the validated path
  - id: path_executor
    type: path_executor
    path_source: validation_loop.response.result.graphscout_router.target
    on_agent_failure: continue
  
  # PHASE 3: Final quality check
  - id: final_summary
    type: local_llm
    model: "gpt-oss:20b"
    provider: "ollama"
    url: "http://localhost:11434/api/generate"
    temperature: 0.3
    prompt: |
      Synthesize the execution results into a final response.
      
      Original query: {{ input }}
      
      {% if previous_outputs.validation_loop %}
      ## Validation Phase
      - Loops: {{ previous_outputs.validation_loop.loops_completed | default('N/A') }}
      - Score: {{ (previous_outputs.validation_loop.final_score | default(0)) | round(3) }}
      - Validated Path: {{ previous_outputs.validation_loop.response.result.graphscout_router.target | default([]) }}
      {% endif %}
      
      {% if previous_outputs.path_executor %}
      ## Execution Phase
      {% set executor = previous_outputs.path_executor.response | default(previous_outputs.path_executor) %}
      - Status: {{ (executor.status | default('unknown')) | upper }}
      - Executed: {{ executor.executed_path | default([]) }}
      - Results: {{ (executor.results | default({})) | length }} agents completed
      
      ### Execution Results:
      {{ (executor.results | default({})) | tojson(indent=2) }}
      {% endif %}
      
      ---
      
      Provide a comprehensive, well-structured final answer based on the execution results.

# ============================================================================
# GraphScout + PathExecutor Pattern
# ============================================================================
#
# This demonstrates the validated execution pattern:
#
# 1. Validation Loop (Planning Phase):
#    - GraphScout proposes optimal agent paths
#    - PlanValidator scores each proposal with boolean criteria
#    - Loop iterates until score threshold is met (0.5)
#
# 2. Path Execution (Execution Phase):
#    - PathExecutor extracts the validated path
#    - Executes each agent in sequence
#    - Accumulates results from all agents
#
# 3. Final Summary (Reporting Phase):
#    - Synthesizes validation and execution results
#    - Provides comprehensive analysis
#
# ============================================================================
# Agent Scoping - CRITICAL
# ============================================================================
#
# Execution agents (web_search, deep_analyzer, etc.) are defined at the TOP LEVEL
# of the agents list, NOT inside the loop's internal_workflow.
#
# Why?
# - GraphScout discovers agents from the orchestrator's global agent registry
# - PathExecutor can only execute agents from the global agent registry
# - Agents defined inside internal_workflow are scoped to that workflow only
#
# These agents are NOT in the orchestrator's execution sequence (line 21-24),
# so they won't auto-execute. They are only discovered by GraphScout and executed
# by PathExecutor when included in the validated path.
#
# ============================================================================

llm:
  provider: "ollama"
  model: "gpt-oss:20b"
  url: "http://localhost:11434/api/generate"
  temperature: 0.3
  max_tokens: 2000

memory:
  backend: "redisstack"
  host: "localhost"
  port: 6379
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  decay_enabled: true
  decay_config:
    max_age_days: 30
    decay_rate: 0.1

