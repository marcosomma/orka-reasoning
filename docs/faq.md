[ğŸ“˜ Getting Start](./getting-started.md) | [ğŸ¤– Advanced Agents](./agents-advanced.md) | [ğŸ” Architecture](./architecture.md) | [ğŸ§  Idea](./index.md) | [ğŸ§ª Extending Agents](./extending-agents.md) | [ğŸ“Š Observability](./observability.md) | [ğŸ“œ YAML Schema](./orka.yaml-schema.md) | [âš™ Runtime Modes](./runtime-modes.md) | [ğŸ” Security](./security.md) | [â“ FAQ](./faq.md)

# OrKa FAQ

### How is this different from LangChain?
LangChain wraps LLM APIs with logic. OrKa defines cognitive structure in YAML + has full introspection.

### Why YAML?
Declarative, composable, versionable. Think: Terraform for thought.

### What happens if an agent fails?
It logs the error. You can define `fallback:` agents to take over. No silent failures.

### Can I run this with local LLMs?
Yes. Via LiteLLM proxy, run with Ollama, LM Studio, Claude, OpenRouter.

### What about security?
Redis/Kafka can be encrypted. PII filters recommended. OrKaUI will support auth soon.

[ğŸ“˜ Getting Start](./getting-started.md) | [ğŸ¤– Advanced Agents](./agents-advanced.md) | [ğŸ” Architecture](./architecture.md) | [ğŸ§  Idea](./index.md) | [ğŸ§ª Extending Agents](./extending-agents.md) | [ğŸ“Š Observability](./observability.md) | [ğŸ“œ YAML Schema](./orka.yaml-schema.md) | [âš™ Runtime Modes](./runtime-modes.md) | [ğŸ” Security](./security.md) | [â“ FAQ](./faq.md)
